# frozen_string_literal: true

class Raif::ModelTools::<%= class_name %> < Raif::ModelTool
  # For example tool implementations, see: 
  # Wikipedia Search Tool: https://github.com/CultivateLabs/raif/blob/main/app/models/raif/model_tools/wikipedia_search_tool.rb
  # Fetch URL Tool: https://github.com/CultivateLabs/raif/blob/main/app/models/raif/model_tools/fetch_url_tool.rb

  # An example of how the LLM should invoke your tool. This should return a hash with name and arguments keys.
  # `to_json` will be called on it and provided to the LLM as an example of how to invoke your tool.
  def self.example_model_invocation
    {
      "name": tool_name,
      "arguments": { }
    }
  end

  # Define your tool's argument schema here. It should be a valid JSON schema.
  # When the model invokes your tool, the arguments it provides will be validated
  # against this schema using JSON::Validator from the json-schema gem.
  def self.tool_arguments_schema
    # For example:
    # {
    #   type: "object",
    #   additionalProperties: false,
    #   required: ["query"],
    #   properties: {
    #     query: {
    #       type: "string",
    #       description: "The query to search for"
    #     }
    #   }
    # }
    # Would expect the model to invoke your tool with an arguments JSON object like:
    # { "query" : "some query here" }
  end

  def self.tool_description
    "Description of your tool that will be provided to the LLM so it knows when to invoke it"
  end

  # When your tool is invoked by the LLM in a Raif::Agent loop, 
  # the results of the tool invocation are provided back to the LLM as an observation.
  # This method should return whatever you want provided to the LLM.
  # For example, if you were implementing a GoogleSearch tool, this might return a JSON
  # object containing search results for the query.
  def self.observation_for_invocation(tool_invocation)
    return "No results found" unless tool_invocation.result.present?

    JSON.pretty_generate(tool_invocation.result)
  end

  # When your tool is invoked in a Raif::Conversation, should the result be automatically provided back to the model?
  # When true, observation_for_invocation will be used to produce the observation provided to the model
  def self.triggers_observation_to_model?
    false
  end

  # When the LLM invokes your tool, this method will be called with a `Raif::ModelToolInvocation` record as an argument.
  # It should handle the actual execution of the tool. 
  # For example, if you are implementing a GoogleSearch tool, this method should run the actual search
  # and store the results in the tool_invocation's result JSON column.
  def self.process_invocation(tool_invocation)
    # Extract arguments from tool_invocation.tool_arguments
    # query = tool_invocation.tool_arguments["query"]
    #
    # Process the invocation and perform the desired action
    # ...
    #
    # Store the results in the tool_invocation
    # tool_invocation.update!(
    #   result: {
    #     # Your result data structure
    #   }
    # )
    #
    # Return the result
    # tool_invocation.result
  end

end